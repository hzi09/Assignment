# 2. ë¹„ì§€ë„í•™ìŠµ(Unsupervised Learning)


## ğŸ—‚ï¸Directory Structure
```bash
ğŸ“¦2. Unsupervised-Learning
 â”£ ğŸ“œMall_Customers.csv
 â”£ ğŸ“œREADME.md
 â”£ ğŸ“œUnsupervised_Learning_v1.ipynb
 â”£ ğŸ“œUnsupervised_Learning_v2.ipynb
 â”— ğŸ“œUnsupervised_Learning_v3.ipynb
``` 
- `Mall_Customers.csv` : ë°ì´í„° CSV íŒŒì¼
- `README.md` : ë””ë ‰í† ë¦¬ êµ¬ì¡°, ê³¼ì œ ë‚´ìš©, ë¬¸ì œ í’€ì´
- `Unsupervised_Learning_v1.ipynb` : ë©”ì¸ ê³¼ì œ
- `Unsupervised_Learning_v1.ipynb` : ë„ì „ ê³¼ì œ - ë‹¤ì–‘í•œ í´ëŸ¬ìŠ¤í„°ë§ ê¸°ë²• ë¹„êµ
- `Unsupervised_Learning_v1.ipynb` : ë„ì „ ê³¼ì œ - ê³ ê° í–‰ë™ ì˜ˆì¸¡ ëª¨ë¸ êµ¬ì¶•


<br>

## ê³¼ì œ ë‚´ìš©
### ğŸ’¡ì£¼ì œ
ê³ ê° ì„¸ë¶„í™” ë¶„ì„

### ğŸ¯ëª©í‘œ
ê³ ê° ë°ì´í„°ì…‹ì„ ì‚¬ìš©í•˜ì—¬ ë¹„ìŠ·í•œ í–‰ë™ì„ ë³´ì´ëŠ” ê³ ê° ê·¸ë£¹ì„ ì‹ë³„í•©ë‹ˆë‹¤.

### ğŸ“–í•™ìŠµë‚´ìš©
- ë¹„ì§€ë„ í•™ìŠµì˜ ê°œë…ì„ ì´í•´í•˜ê³ , í´ëŸ¬ìŠ¤í„°ë§ ê¸°ë²•ì„ í†µí•´ ë°ì´í„°ì˜ íŒ¨í„´ì„ ë°œê²¬í•˜ëŠ” ëŠ¥ë ¥
- ë°ì´í„° ì „ì²˜ë¦¬ ë° íƒìƒ‰: ë¹„ì§€ë„ í•™ìŠµì—ì„œì˜ ë°ì´í„° ì¤€ë¹„ ê³¼ì •
- í´ëŸ¬ìŠ¤í„°ë§ ê¸°ë²• ì ìš©: ë‹¤ì–‘í•œ í´ëŸ¬ìŠ¤í„°ë§ ì•Œê³ ë¦¬ì¦˜ì˜ ì´í•´ì™€ ì‹¤ìŠµ
- ìµœì ì˜ í´ëŸ¬ìŠ¤í„° ìˆ˜ ê²°ì •: ëª¨ë¸ì˜ ì„±ëŠ¥ì„ í‰ê°€í•˜ëŠ” ë°©ë²•ê³¼ ì‹œê°í™” ê¸°ìˆ ì„ í†µí•´ ì¸ì‚¬ì´íŠ¸ ë„ì¶œ


## ê³¼ì œ ê°€ì´ë“œ
- **ë°ì´í„°ì…‹ íƒìƒ‰ ë° ì „ì²˜ë¦¬**:
    - ê²°ì¸¡ì¹˜ ì²˜ë¦¬
    - ìŠ¤ì¼€ì¼ë§
        - ë°ì´í„°ì˜ ìŠ¤ì¼€ì¼ì„ ì¡°ì •í•˜ê¸° ìœ„í•´ í‘œì¤€í™”(Standardization) ë˜ëŠ” ì •ê·œí™”(Normalization)ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤
- **í´ëŸ¬ìŠ¤í„°ë§ ê¸°ë²• ì ìš©**:
    - K-means
    - ê³„ì¸µì  êµ°ì§‘í™”
    - DBSCAN ë“±ì˜ ì•Œê³ ë¦¬ì¦˜
- **ìµœì ì˜ í´ëŸ¬ìŠ¤í„° ìˆ˜ ê²°ì •**:
    - ì—˜ë³´ìš° ë°©ë²• ë˜ëŠ” ì‹¤ë£¨ì—£ ì ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ìµœì ì˜ í´ëŸ¬ìŠ¤í„° ìˆ˜ë¥¼ ì°¾ìŠµë‹ˆë‹¤.
- **ê²°ê³¼ ì‹œê°í™”**:
    - í´ëŸ¬ìŠ¤í„°ë§ ê²°ê³¼ë¥¼ 2D ë˜ëŠ” 3Dë¡œ ì‹œê°í™”í•˜ì—¬ ê³ ê° ì„¸ë¶„í™” ê²°ê³¼ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤.
        - **ì‹œê°í™”**: matplotlib ë˜ëŠ” seabornì„ ì‚¬ìš©í•˜ì—¬ í´ëŸ¬ìŠ¤í„°ë¥¼ ìƒ‰ìƒìœ¼ë¡œ êµ¬ë¶„í•˜ì—¬ ì‹œê°í™”í•©ë‹ˆë‹¤. 2D í”Œë¡¯ì„ ì‚¬ìš©í•˜ì—¬ ê° í´ëŸ¬ìŠ¤í„°ë¥¼ ë‹¤ë¥¸ ìƒ‰ìœ¼ë¡œ í‘œí˜„í•©ë‹ˆë‹¤.



<br>

## ğŸ”¥ì¶”ê°€ ë„ì „ ê³¼ì œ
- **ë‹¤ì–‘í•œ í´ëŸ¬ìŠ¤í„°ë§ ê¸°ë²• ë¹„êµ** â­â­â­â­
    - DBSCAN ì™¸ì— Gaussian Mixture Model(GMM)ì™€ ê°™ì€ ë‹¤ë¥¸ í´ëŸ¬ìŠ¤í„°ë§ ê¸°ë²•ì„ ì ìš©í•˜ê³  ì„±ëŠ¥ì„ ë¹„êµí•©ë‹ˆë‹¤.
- **ê³ ê° í–‰ë™ ì˜ˆì¸¡ ëª¨ë¸ êµ¬ì¶•** â­â­â­â­â­
    - í´ëŸ¬ìŠ¤í„°ë§ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ íŠ¹ì • í´ëŸ¬ìŠ¤í„°ì— ì†í•˜ëŠ” ê³ ê°ì˜ í–‰ë™ì„ ì˜ˆì¸¡í•˜ëŠ” ë¶„ë¥˜ ëª¨ë¸ì„ êµ¬ì¶•í•©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, êµ¬ë§¤ ê°€ëŠ¥ì„±ì„ ì˜ˆì¸¡í•˜ëŠ” ëª¨ë¸ì„ ë§Œë“¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
- **ì‹œê³„ì—´ ë¶„ì„**â­â­â­â­
    - ê³ ê°ì˜ í–‰ë™ ë³€í™”ë¥¼ ì‹œê°„ì— ë”°ë¼ ë¶„ì„í•˜ì—¬ íŠ¹ì • ê·¸ë£¹ì˜ íŠ¸ë Œë“œë¥¼ ì‹œê³„ì—´ ë°ì´í„°ë¡œ ì‹œê°í™”í•©ë‹ˆë‹¤.

- ì°¸ê³  : ì‹œê³„ì—´ ë¶„ì„ì€ ì§„í–‰í•˜ì§€ ëª»í•¨.

<br>

## âœï¸ë¬¸ì œ í’€ì´
### ë°ì´í„°ì…‹ íƒìƒ‰ ë° ì „ì²˜ë¦¬
#### 1. ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸° ë° í™•ì¸
- í•™ìŠµì„ ì§„í–‰í•˜ê¸° ì „ì— ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ê³  í™•ì¸
  - CSV íŒŒì¼ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸° : `read_csv()`
  - ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°(5ê°œì˜ í–‰ë§Œ í™•ì¸) : `head()`
  - ë°ì´í„°ì…‹ì˜ ê¸°ë³¸ ì •ë³´ í™•ì¸ : `info()`
    - ë°ì´í„° íƒ€ì…, ì¸ë±ìŠ¤ ê°œìˆ˜, ì»¬ëŸ¼ëª… ë“±ì„ í™•ì¸ ê°€ëŠ¥
  - ê²°ì¸¡ì¹˜ í™•ì¸ `isna().sum()`
    - ê²°ì¸¡ì¹˜ëŠ” 0ìœ¼ë¡œ í™•ì¸ë˜ì–´ì„œ ë”°ë¡œ ì²˜ë¦¬í•  í•„ìš”ê°€ ì—†ìŒ
    ```python
    import pandas as pd

    # ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
    mall = pd.read_csv('CSV/Mall_Customers.csv')

    # ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°
    mall.head()

    # ë°ì´í„° ì •ë³´í™•ì¸
    mall.info()

    # ê²°ì¸¡ì¹˜ í™•ì¸
    mall.isna().sum()
    ```

#### 2. ë°ì´í„° ì „ì²˜ë¦¬
- ë°ì´í„° ë¶„ì„ì— ì‚¬ìš©í•˜ì§€ ì•ŠëŠ” ì»¬ëŸ¼ ì œê±° : `drop()`
  - ê·¸ëƒ¥ ì¸ë±ìŠ¤ ì—­í• ì„ í•˜ëŠ” `CustomerID`ì™€ 0, 1ë¡œ ë  `Gender`ëŠ” ì œì™¸
    ```python
    # ë¶„ì„ì— ì‚¬ìš©í•˜ì§€ ì•ŠëŠ” ì»¬ëŸ¼ ì œê±°
    mall = mall.drop(columns=['CustomerID', 'Gender'])
    ```

- ì´ìƒì¹˜ í™•ì¸ ë° ì²˜ë¦¬
  - ì´ìƒì¹˜ ì²˜ë¦¬ ì „ì— ê¸°ì¡´ì˜ ë°ì´í„°ì™€ ë¹„êµë¥¼ í•˜ê³  ì‹¶ì–´ì„œ `mall_processed` ë³€ìˆ˜ë¥¼ ë§Œë“¤ì–´ì„œ ë°ì´í„°ë¥¼ ë³µì‚¬(`copy()`)í•´ ë„£ì–´ì¤Œ
  - ì´ìƒì¹˜ëŠ” IQR ë°©ì‹ìœ¼ë¡œ ì²˜ë¦¬í•˜ì˜€ìœ¼ë©° ìƒí•œ ë° í•˜í•œê°’ìœ¼ë¡œ ëŒ€ì²´í•˜ëŠ” ë°©ë²•ì„ ì±„íƒ 
    ```python
    import numpy as np

    numerical_columns = mall.select_dtypes(include=[np.number]).columns
    mall_processed = mall.copy()

    for col in numerical_columns:
        Q1 = mall[col].quantile(0.25)
        Q3 = mall[col].quantile(0.75)
        IQR = Q3 - Q1
        lower_bound = Q1 - 1.5 * IQR
        upper_bound = Q3 + 1.5 * IQR
        outliers = ((mall[col] < lower_bound) | (mall[col] > upper_bound))
        if outliers.sum() > 0:
            # ì´ìƒì¹˜ë¥¼ ìƒí•œ ë° í•˜í•œê°’ìœ¼ë¡œ ëŒ€ì²´
            mall_processed[col] = np.where(mall_processed[col] < lower_bound, lower_bound, mall_processed[col])
            mall_processed[col] = np.where(mall_processed[col] > upper_bound, upper_bound, mall_processed[col])
    ```

  - ì´ìƒì¹˜ ì²˜ë¦¬ ì „ í›„ë¥¼ ì‹œê°í™”í•˜ì—¬ í‘œí˜„
    ```python
    import matplotlib.pyplot as plt

    # ì´ìƒì¹˜ ì²˜ë¦¬ ì „ ë°ì´í„° ì‹œê°í™”
    mall.boxplot()
    plt.xticks(rotation=90)
    plt.title('Before Boxplot')
    plt.tight_layout()
    plt.show()

    # ì´ìƒì¹˜ ì²˜ë¦¬ í›„ ë°ì´í„° ì‹œê°í™”
    mall_processed.boxplot()
    plt.xticks(rotation=90)
    plt.title('After Boxplot')
    plt.tight_layout()
    plt.show()
    ```
    ![image](https://github.com/user-attachments/assets/e728ac21-2e57-4181-ae45-b58638632d79)


- ìŠ¤ì¼€ì¼ë§
  - StandardScalerë¥¼ ì‚¬ìš©í•˜ì—¬ ìˆ«ìí˜• í”¼ì²˜ ê°’ë“¤ì„ í‰ê· ì´ 0ì´ê³  í‘œì¤€í¸ì°¨ê°€ 1ì´ ë˜ë„ë¡ ë³€í™˜
    ```python
    from sklearn.preprocessing import StandardScaler

    # ìˆ«ìí˜• ì»¬ëŸ¼ ì„ íƒ ë° ìŠ¤ì¼€ì¼ë§
    scaler = StandardScaler()
    data_scaled = scaler.fit_transform(mall_processed[numerical_columns])
    ```

#### 3. í´ëŸ¬ìŠ¤í„°ë§ ê¸°ë²• ì ìš©

- K-means
  - ìµœì ì˜ kë¥¼ ì°¾ê¸°ìœ„í•œ 'ì—˜ë³´ìš° ë°©ë²•' ì‚¬ìš©
    ```python
    from sklearn.cluster import KMeans

    # ìµœì ì˜ kì°¾ê¸° (ì—˜ë³´ìš° ë°©ë²•)
    inertia = []
    K = range(1, 11)
    for k in K:
        kmeans = KMeans(n_clusters=k, random_state=42)
        kmeans.fit(data_scaled)
        inertia.append(kmeans.inertia_)
    
    # ì—˜ë³´ìš° ê·¸ë˜í”„
    plt.figure(figsize=(10, 5))
    plt.plot(K, inertia, 'bx-')
    plt.title('Elbow Method for Optimal k')
    plt.xlabel('Number of Clusters (k)')
    plt.ylabel('Inertia')
    plt.show()
    ```
  - ì—˜ë³´ìš° ê·¸ë˜í”„
    - 4~6ì´ ì ë‹¹í•˜ë‹¤ê³  íŒë‹¨í–ˆì§€ë§Œ, ì •í™•í•˜ê²Œ ì•Œ ìˆ˜ê°€ ì—†ì–´ì„œ ì‹¤ë£¨ì—£ ê³„ìˆ˜ë¥¼ í™•ì¸
    ![image](https://github.com/user-attachments/assets/08515199-80fa-4ede-a649-9bec7e0167fc)
  - ì‹¤ë£¨ì—£ ê³„ìˆ˜
    ```python
    from sklearn.metrics import silhouette_score

    # ìµœì  í´ëŸ¬ìŠ¤í„° ìˆ˜(k = 6)ë¡œ ëª¨ë¸ ìƒì„± ë° í•™ìŠµ
    optimal_k = 6
    kmeans = KMeans(n_clusters=optimal_k, random_state=42)
    kmeans_labels = kmeans.fit_predict(data_scaled)
    kmeans_silhouette = silhouette_score(data_scaled, kmeans_labels)
    print(f'ì‹¤ë£¨ì—£ ê³„ìˆ˜: {kmeans_silhouette}')
    ```
    - ì‹¤ë£¨ì—£ ê³„ìˆ˜ê°€ 6ì´ ê°€ì¥ ì¢‹ì€ ê²°ê³¼ë¥¼ ë³´ì—¬ì£¼ì–´ k = 6ìœ¼ë¡œ ì‹œê°í™”
      | í´ëŸ¬ìŠ¤í„° ìˆ˜ |      4 |       5 |       6 |
      |------------:|-------:|--------:|--------:|
      | ì‹¤ë£¨ì—£ ê³„ìˆ˜ | 0.4045 | 0.40922 | 0.43194 |

  - ê³„ì¸µì  êµ°ì§‘í™”, DBSCANë„ ì§„í–‰


#### 4.ê²°ê³¼ ì‹œê°í™”
- ì„¸ê°œì˜ ëª¨ë¸ ëª¨ë‘ Annual Income vs Spending Scoreì˜ êµ°ì§‘í™”ê°€ ê°€ì¥ ì˜ ë˜ì–´ìˆëŠ” ê²ƒì„ í™•ì¸
  ![image](https://github.com/user-attachments/assets/15dc40c3-79b6-4522-8c60-6f4180e94696)
- ê°ê°ì˜ ëª¨ë¸ì˜ ì‹¤ë£¨ì—£ ê³„ìˆ˜ë¥¼ ë¹„êµ
  ```python
  # ëª¨ë¸ë³„ ì„±ëŠ¥ ì €ì¥
  results = pd.DataFrame({
      'Model': ['K-means', 'Agglomerative Clustering', 'DBSCAN'],
      'Silhouette_score': [kmeans_silhouette, hc_silhouette, best_DBSCAN_silhouette]
  })

  # ì„œë¸Œí”Œë¡¯ ìƒì„±
  fig = plt.figure(figsize=(18, 5))  

  plt.bar(results['Model'], results['Silhouette_score'], color='purple', width=0.5)
  plt.title('Silhouette_score Comparison')
  plt.ylabel('Silhouette_score Value')
  plt.xlabel('Model')
  plt.grid(axis='y', linestyle='--', alpha=0.7)

  # ë ˆì´ì•„ì›ƒ ì¡°ì • ë° ì¶œë ¥
  plt.show()
  ```
  ![image](https://github.com/user-attachments/assets/9cc3e2ea-94d0-4b18-a496-370479ccfd47)

- KMeansì˜ ì‹¤ë£¨ì—£ ê³„ìˆ˜ê°€ ê°€ì¥ ë†’ìŒ


## âœï¸ ë„ì „ê³¼ì œ ë¬¸ì œ í’€ì´
### ë‹¤ì–‘í•œ í´ëŸ¬ìŠ¤í„°ë§ ê¸°ë²• ë¹„êµ
- Gaussian Mixture Model(GMM) í´ë¦¬ìŠ¤í„°ë§ ê¸°ë²•ì„ ì ìš©
  ```python
  from sklearn.mixture import GaussianMixture

  # GMM ëª¨ë¸ ìƒì„±
  gmm = GaussianMixture(n_components=5, covariance_type='full')

  # ëª¨ë¸ í•™ìŠµ ë° ì˜ˆì¸¡
  mall_processed['Cluster'] = gmm.fit_predict(data_scaled)
  ```
  - ì‹¤ë£¨ì—£ ê³„ìˆ˜ëŠ” '0.4072'ê°€ ë‚˜ì˜´
  ![image](https://github.com/user-attachments/assets/1df80739-2fc1-405c-9b4b-442b44a8a81e)



### ê³ ê° í–‰ë™ ì˜ˆì¸¡ ëª¨ë¸ êµ¬ì¶•
- ê³„ì¸µì  êµ°ì§‘í™”ëª¨ë¸ì´ êµ°ì§‘í™”ê°€ ì˜ë˜ì–´ìˆë‹¤ê³  ìƒê°ë˜ì–´ ê³„ì¸µì  êµ°ì§‘í™” ëª¨ë¸ì˜ í´ë¦¬ìŠ¤í„°ë¥¼ ì‚¬ìš©
- Genderì„ í¬í•¨ì‹œí‚¤ëŠ” ê²ƒì´ ë‚«ë‹¤ê³  íŒë‹¨ë˜ì–´ Geder ì»¬ëŸ¼ì˜ ë°ì´í„° ì¸ì½”ë”©ì„ ì§„í–‰
  - One Hot Encoderë¥¼ ì‚¬ìš©í•˜ì—¬ Gender_Male ì»¬ëŸ¼ì„ ìƒì„±(Gender ë°ì´í„°ê°€ Maleì´ë©´ 1, Femaleì´ë©´ 0)
    ```python
    from sklearn.preprocessing import OneHotEncoder

    one_hot_encoder = OneHotEncoder(sparse_output=False, drop='first', dtype='int')
    gender_encoded = one_hot_encoder.fit_transform(mall[['Gender']])
    gender_encoded_df = pd.DataFrame(gender_encoded, columns=one_hot_encoder.get_feature_names_out(['Gender']))
    mall = pd.concat([mall.drop(columns=['Gender']), gender_encoded_df], axis=1)
    ```

- ë¶„ë¥˜ëª¨ë¸
  - í´ë¦¬ìŠ¤í„°ë¥¼ íƒ€ê²Ÿìœ¼ë¡œ ê²°ì •
    ```python
    # í•´ë‹¹ í´ëŸ¬ìŠ¤í„°ë¥¼ íƒ€ê²Ÿìœ¼ë¡œ ê²°ì •
    mall_processed['Target'] = (mall_processed['Cluster'] == 5)
    mall_processed
    ```
  
  - ì˜ì‚¬ê²°ì •ë‚˜ë¬´ë¡œ í›ˆë ¨ì§„í–‰
    ```python
    from sklearn.model_selection import train_test_split

    # ì…ë ¥ ë³€ìˆ˜ì™€ íƒ€ê²Ÿ ë³€ìˆ˜
    X = mall_processed.drop(columns=['Cluster', 'Target']) 
    y = mall_processed['Target']

    # ë°ì´í„° ë¶„ë¦¬
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    from sklearn.tree import DecisionTreeClassifier
    from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

    # ëª¨ë¸ ìƒì„± ë° í•™ìŠµ
    model = DecisionTreeClassifier(random_state=42)
    model.fit(X_train, y_train)

    # ì˜ˆì¸¡
    y_pred = model.predict(X_test)

    # ëª¨ë¸ í‰ê°€
    accuracy = accuracy_score(y_test, y_pred)
    ppv = precision_score(y_test, y_pred)
    recall = recall_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred)

    print(f"Accuracy: {accuracy}")
    print(f"Precision: {ppv}")
    print(f'Recall: {recall}')
    print(f'F1 scorer : {f1}')
    ```
    - ê²°ê³¼
      ```
      Accuracy: 0.925
      Precision: 1.0
      Recall: 0.7272727272727273
      F1 scorer : 0.8421052631578947
      ```